{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n",
      "Target: 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: quality, dtype: int64\n",
      "Data:    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  \n",
      "0      9.4  \n",
      "1      9.8  \n",
      "2      9.8  \n",
      "3      9.8  \n",
      "4      9.4  \n",
      "(1599, 11)\n",
      "(1599, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a Pandas DataFrame\n",
    "csv_file = './winequality/winequality-red.csv'\n",
    "df = pd.read_csv(csv_file, delimiter=';')\n",
    "\n",
    "# Print the column names to debug\n",
    "print(\"Column names:\", df.columns)\n",
    "\n",
    "\n",
    "# Assuming df is your data frame and 'quality' is the column you want to predict\n",
    "target = df.pop('quality')\n",
    "# Convert quality into binary classification (1 for quality >= 6, otherwise 0)\n",
    "target = target.apply(lambda x: 1 if x >= 6 else 0)\n",
    "\n",
    "#Pop top 5 rows for testing\n",
    "\n",
    "print(\"Target:\", target.head())\n",
    "print(\"Data:\", df.head())\n",
    "\n",
    "\n",
    "# Convert the DataFrame and the target column to TensorFlow tensors\n",
    "y_train = tf.convert_to_tensor(target.values, dtype=tf.float32, name='y_train')\n",
    "X_train = tf.convert_to_tensor(df.values, dtype=tf.float32, name='X_train')\n",
    "\n",
    "y_train = tf.reshape(y_train, (-1, 1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "class LogisticRegressionModel(tf.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        # Initialize weights and bias\n",
    "        self.w = tf.Variable(tf.random.normal([input_dim, 1]), name='weights')\n",
    "        self.b = tf.Variable(tf.zeros([1]), name='bias')\n",
    "\n",
    "    def __call__(self, X):\n",
    "        # Linear combination with sigmoid activation\n",
    "        logits = tf.matmul(X, self.w) + self.b\n",
    "        return tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Loss function Binary Cross Entropy\n",
    "def loss_fn(model, X, y):\n",
    "    y_pred = model(X)\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training step\n",
    "def train_step(model, X, y, learning_rate=0.01):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, X, y)\n",
    "    gradients = tape.gradient(loss, [model.w, model.b])\n",
    "    model.w.assign_sub(learning_rate * gradients[0])\n",
    "    model.b.assign_sub(learning_rate * gradients[1])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7785525321960449\n",
      "Epoch 1000, Loss: 0.7785525321960449\n",
      "Epoch 2000, Loss: 0.7785525321960449\n",
      "Epoch 3000, Loss: 0.7785525321960449\n",
      "Epoch 4000, Loss: 0.7785525321960449\n",
      "Epoch 5000, Loss: 0.7785525321960449\n",
      "Epoch 6000, Loss: 0.7785525321960449\n",
      "Epoch 7000, Loss: 0.7785525321960449\n",
      "Epoch 8000, Loss: 0.7785525321960449\n",
      "Epoch 9000, Loss: 0.7785525321960449\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "model = LogisticRegressionModel(input_dim=X_train.shape[1])\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(model, X_train, y_train, learning_rate=0.01)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[1.]]\n",
      "Accuracy: 0.5347091932457786\n",
      "Precision: 0.5347091932457786\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "X_test = np.array([[7,0.30,0.55,1,0.040,6,12,0.97,2.66,0.69,11.7]])\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test_pred = model(X_test)\n",
    "print(\"Predictions:\", y_test_pred.numpy())\n",
    "\n",
    "# Predict using the trained model (binary output)\n",
    "y_train_pred = model(X_train)\n",
    "y_train_pred = tf.round(y_train_pred)  # Convert probabilities to binary outcomes (0 or 1)\n",
    "\n",
    "# Convert tensors to numpy arrays for metric calculation\n",
    "y_train_true_np = y_train.numpy()\n",
    "y_train_pred_np = y_train_pred.numpy()\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "accuracy = accuracy_score(y_train_true_np, y_train_pred_np)\n",
    "precision = precision_score(y_train_true_np, y_train_pred_np)\n",
    "recall = recall_score(y_train_true_np, y_train_pred_np)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
