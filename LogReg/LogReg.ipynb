{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.7640524   0.4001572 ]\n",
      " [ 0.978738    2.2408931 ]\n",
      " [ 1.867558   -0.9772779 ]\n",
      " [ 0.95008844 -0.1513572 ]\n",
      " [-0.10321885  0.41059852]\n",
      " [ 0.14404356  1.4542735 ]\n",
      " [ 0.7610377   0.12167501]\n",
      " [ 0.44386324  0.33367434]\n",
      " [ 1.4940791  -0.20515826]\n",
      " [ 0.3130677  -0.85409576]\n",
      " [-2.5529897   0.6536186 ]\n",
      " [ 0.8644362  -0.742165  ]\n",
      " [ 2.2697546  -1.4543657 ]\n",
      " [ 0.04575852 -0.18718386]\n",
      " [ 1.5327792   1.4693588 ]\n",
      " [ 0.15494743  0.37816253]\n",
      " [-0.88778573 -1.9807965 ]\n",
      " [-0.34791216  0.15634897]\n",
      " [ 1.2302907   1.2023798 ]\n",
      " [-0.3873268  -0.30230275]\n",
      " [-1.048553   -1.420018  ]\n",
      " [-1.7062702   1.9507754 ]\n",
      " [-0.5096522  -0.4380743 ]\n",
      " [-1.2527953   0.7774904 ]\n",
      " [-1.6138978  -0.21274029]\n",
      " [-0.89546657  0.3869025 ]\n",
      " [-0.51080513 -1.1806322 ]\n",
      " [-0.02818223  0.42833188]\n",
      " [ 0.06651722  0.3024719 ]\n",
      " [-0.6343221  -0.36274117]\n",
      " [-0.67246044 -0.35955316]\n",
      " [-0.8131463  -1.7262826 ]\n",
      " [ 0.17742614 -0.40178093]\n",
      " [-1.6301984   0.46278226]\n",
      " [-0.9072984   0.0519454 ]\n",
      " [ 0.7290906   0.12898292]\n",
      " [ 1.1394007  -1.2348258 ]\n",
      " [ 0.40234163 -0.6848101 ]\n",
      " [-0.87079716 -0.5788497 ]\n",
      " [-0.31155252  0.05616534]\n",
      " [-1.1651498   0.9008265 ]\n",
      " [ 0.46566245 -1.5362437 ]\n",
      " [ 1.4882522   1.8958892 ]\n",
      " [ 1.1787796  -0.17992483]\n",
      " [-1.0707526   1.0544517 ]\n",
      " [-0.40317693  1.222445  ]\n",
      " [ 0.20827498  0.97663903]\n",
      " [ 0.3563664   0.7065732 ]\n",
      " [ 0.01050002  1.7858706 ]\n",
      " [ 0.12691209  0.40198937]\n",
      " [ 1.8831507  -1.347759  ]\n",
      " [-1.270485    0.9693967 ]\n",
      " [-1.1731234   1.9436212 ]\n",
      " [-0.41361898 -0.7474548 ]\n",
      " [ 1.922942    1.4805148 ]\n",
      " [ 1.867559    0.90604466]\n",
      " [-0.86122566  1.9100649 ]\n",
      " [-0.26800337  0.8024564 ]\n",
      " [ 0.947252   -0.15501009]\n",
      " [ 0.61407936  0.9222067 ]\n",
      " [ 0.37642553 -1.0994008 ]\n",
      " [ 0.2982382   1.3263859 ]\n",
      " [-0.69456786 -0.14963454]\n",
      " [-0.43515354  1.8492638 ]\n",
      " [ 0.67229474  0.40746182]\n",
      " [-0.76991606  0.5392492 ]\n",
      " [-0.6743327   0.03183056]\n",
      " [-0.6358461   0.67643327]\n",
      " [ 0.57659084 -0.20829876]\n",
      " [ 0.3960067  -1.0930616 ]\n",
      " [-1.4912575   0.4393917 ]\n",
      " [ 0.1666735   0.63503146]\n",
      " [ 2.3831449   0.94447947]\n",
      " [-0.91282225  1.1170163 ]\n",
      " [-1.3159074  -0.4615846 ]\n",
      " [-0.0682416   1.7133427 ]\n",
      " [-0.74475485 -0.82643855]\n",
      " [-0.09845252 -0.6634783 ]\n",
      " [ 1.1266359  -1.0799315 ]\n",
      " [-1.1474687  -0.43782005]\n",
      " [-0.49803245  1.929532  ]\n",
      " [ 0.9494208   0.08755124]\n",
      " [-1.2254355   0.844363  ]\n",
      " [-1.0002153  -1.5447711 ]\n",
      " [ 1.1880298   0.3169426 ]\n",
      " [ 0.9208588   0.31872764]\n",
      " [ 0.8568306  -0.6510256 ]\n",
      " [-1.0342429   0.6815945 ]\n",
      " [-0.80340964 -0.6895498 ]\n",
      " [-0.4555325   0.01747916]\n",
      " [-0.35399392 -1.3749512 ]\n",
      " [-0.6436184  -2.2234032 ]\n",
      " [ 0.62523144 -1.6020577 ]\n",
      " [-1.1043833   0.05216508]\n",
      " [-0.739563    1.5430146 ]\n",
      " [-1.2928569   0.26705086]\n",
      " [-0.03928282 -1.1680934 ]\n",
      " [ 0.5232767  -0.17154633]\n",
      " [ 0.77179056  0.82350415]\n",
      " [ 2.163236    1.336528  ]], shape=(100, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]], shape=(100, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Generate some synthetic data for demonstration\n",
    "np.random.seed(0)\n",
    "X_train = np.random.randn(100, 2)\n",
    "y_train = (np.sum(X_train, axis=1) > 0).astype(np.double).reshape(-1, 1)\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "class LogisticRegressionModel(tf.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        self.w = tf.Variable(tf.random.normal([input_dim, 1], dtype=tf.float32))\n",
    "        self.b = tf.Variable(tf.zeros([1], dtype=tf.float32))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return tf.sigmoid(tf.matmul(x, self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Loss function Binary Cross Entropy\n",
    "def loss_fn(model, X, y):\n",
    "    y_pred = model(X)\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training step\n",
    "def train_step(model, X, y, learning_rate=0.01):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, X, y)\n",
    "    gradients = tape.gradient(loss, [model.w, model.b])\n",
    "    model.w.assign_sub(learning_rate * gradients[0])\n",
    "    model.b.assign_sub(learning_rate * gradients[1])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7016971111297607\n",
      "Epoch 100, Loss: 0.6960114240646362\n",
      "Epoch 200, Loss: 0.6904492974281311\n",
      "Epoch 300, Loss: 0.6850141286849976\n",
      "Epoch 400, Loss: 0.6797075867652893\n",
      "Epoch 500, Loss: 0.6745308041572571\n",
      "Epoch 600, Loss: 0.6694850921630859\n",
      "Epoch 700, Loss: 0.6645722389221191\n",
      "Epoch 800, Loss: 0.6597944498062134\n",
      "Epoch 900, Loss: 0.6551554203033447\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "model = LogisticRegressionModel(input_dim=2)\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(model, X_train, y_train)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.9348848 ]\n",
      " [0.04383444]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "X_test = np.array([[1.0, 2.0], [-1.0, -2.0]])\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test_pred = model(X_test)\n",
    "print(\"Predictions:\", y_test_pred.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
